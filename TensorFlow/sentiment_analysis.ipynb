{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pad_sequences(train_data, MAXLEN)\n",
    "test_data = pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 00:48:46.687250: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE,32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 103s 159ms/step - loss: 0.0862 - acc: 0.9711 - val_loss: 0.3342 - val_acc: 0.8876\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 0.0749 - acc: 0.9760 - val_loss: 0.4007 - val_acc: 0.8832\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 91s 146ms/step - loss: 0.0673 - acc: 0.9778 - val_loss: 0.5046 - val_acc: 0.8734\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 73s 116ms/step - loss: 0.0592 - acc: 0.9804 - val_loss: 0.4167 - val_acc: 0.8850\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 78s 125ms/step - loss: 0.0527 - acc: 0.9830 - val_loss: 0.6446 - val_acc: 0.8428\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 66s 105ms/step - loss: 0.0479 - acc: 0.9837 - val_loss: 0.3852 - val_acc: 0.8858\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 70s 112ms/step - loss: 0.0427 - acc: 0.9862 - val_loss: 0.4687 - val_acc: 0.8830\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 80s 127ms/step - loss: 0.0384 - acc: 0.9884 - val_loss: 0.4247 - val_acc: 0.8752\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 70s 112ms/step - loss: 0.0319 - acc: 0.9905 - val_loss: 0.6116 - val_acc: 0.8554\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 71s 113ms/step - loss: 0.0319 - acc: 0.9905 - val_loss: 0.4747 - val_acc: 0.8752\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "            optimizer=\"rmsprop\",\n",
    "            metrics=['acc'])\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluation(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.preprocessing.text' has no attribute 'text_to_sequence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb#ch0000005?line=4'>5</a>\u001b[0m     tokens \u001b[39m=\u001b[39m [word_index[word] \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m word_index \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m tokens]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb#ch0000005?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pad_sequences([tokens], MAXLEN)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb#ch0000005?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(encode_text(\u001b[39m\"\u001b[39;49m\u001b[39mhello my name is\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;32m/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb Cell 6'\u001b[0m in \u001b[0;36mencode_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_text\u001b[39m(text):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb#ch0000005?line=3'>4</a>\u001b[0m     tokens \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mpreprocessing\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49mtext_to_sequence(text) \u001b[39m#단어를 하나하나로 나누눈거\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb#ch0000005?line=4'>5</a>\u001b[0m     tokens \u001b[39m=\u001b[39m [word_index[word] \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m word_index \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m tokens]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/euncheolj/Downloads/StudyStuff/TensorFlow/sentiment_analysis.ipynb#ch0000005?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pad_sequences([tokens], MAXLEN)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.preprocessing.text' has no attribute 'text_to_sequence'"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = tf.keras.preprocessing.text.text_to_sequence(text) #단어를 하나하나로 나누눈거\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return pad_sequences([tokens], MAXLEN)\n",
    "\n",
    "print(encode_text(\"hello my name is\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = {value:key for (value, key) in word_index.items()}\n",
    "\n",
    "def decode_text(array):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for word in array:\n",
    "        if word != PAD:\n",
    "            text += reverse_word_index[word]\n",
    "    return text[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred)\n",
    "    return result[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
